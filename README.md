# First Project for a Data Science Class

This repository contains a data science project that analyzes historical node/edge data, derives graph-based power broker scores, and assigns modern-day wealth classifications to sites. A machine learning model is used to assess the association of this archaelogical data with modern day wealth classifications of the locations

## File Index (Detailed Purpose + Links)

- [`README.md`](README.md): Project overview, file guide, and quick usage notes for reproducing the analysis.
- [`question_understanding.md`](question_understanding.md): First step in the CRISP-DM process. Questions to be answered. 
- [`analysis.ipynb`](analysis.ipynb): Main analysis notebook. Intended for end-to-end exploration, data prep, and visual/statistical answers to project questions.
- [`model.ipynb`](model.ipynb): Supplemental notebook for additional modeling or alternative analysis approaches (used if you split experiments from the main notebook).
- [`build_power_brokers.py`](build_power_brokers.py): Builds a directed igraph from `orbis_nodes_0514.csv` and `orbis_edges_0514.csv`, then computes directed closeness centrality twice: once with all edges, and once with edges where `type != "road"`. Outputs node scores to `orbis_nodes_0514_with_power_broker_scores.csv`.
- [`classify_sites_wealth.py`](classify_sites_wealth.py): Reads `sites_extended.csv` and classifies each record as `Wealthy`, `Medium Wealthy`, or `Poor` using the OpenAI API. Outputs `sites_extended_with_wealth_class.csv`. Requires `OPENAI_API_KEY` in `.env`.
- [`orbis_nodes_0514.csv`](orbis_nodes_0514.csv): Raw node list with `id`, `label`, and coordinates (`x`, `y`).
- [`orbis_edges_0514.csv`](orbis_edges_0514.csv): Raw directed edge list with `source`, `target`, cost/time fields (`km`, `days`, `expense`), and `type` (e.g., `road`).
- [`orbis_nodes_0514_with_power_broker_scores.csv`](orbis_nodes_0514_with_power_broker_scores.csv): Node table with appended centrality scores (`closeness_all_edges`, `closeness_no_road_edges`) generated by `build_power_brokers.py`.
- [`sites_extended.csv`](sites_extended.csv): Site metadata (e.g., `province`, `modern`, and other attributes used for classification).
- [`sites_extended_with_wealth_class.csv`](sites_extended_with_wealth_class.csv): `sites_extended.csv` plus a `wealth_class` column produced by `classify_sites_wealth.py`.
- [`final_data_set.csv`](final_data_set.csv): Final merged dataset that combines node scores with `wealth_class` on `id`.


## Suggested Notebook Structure (CRISP-DM)

1. **Business Understanding:** State 3â€“5 questions and why they matter.
2. **Data Understanding:** Describe data sources and key columns.
3. **Data Preparation:** Cleaning steps, missing value handling, categorical encoding.
4. **Modeling / Analysis:** Graph metrics, statistics, or ML models (if needed).
5. **Evaluation:** Validate findings and discuss limitations.
6. **Deployment / Reporting:** Summarize insights and outputs.

## Quick Usage

1. Compute power broker scores:
   - `python build_power_brokers.py`
2. Classify site wealth:
   - Add `OPENAI_API_KEY` to `.env`
   - `python classify_sites_wealth.py`
3. Merge outputs into `final_data_set.csv`:
   - Use the provided merge snippet in your notebook or a small script.
